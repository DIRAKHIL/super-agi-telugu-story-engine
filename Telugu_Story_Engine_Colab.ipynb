{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# 🎭 Telugu Story Engine - Production AI System\n",
        "\n",
        "## 🚀 PRODUCTION-READY REAL AI SYSTEM - 100% Open Source\n",
        "\n",
        "**✅ REAL AI MODELS • ❌ NO MOCKS • ❌ NO FALLBACKS • ❌ NO DEMOS**\n",
        "\n",
        "### Features:\n",
        "- 🧠 **4 Real AI Models**: Telugu BERT, GPT-2, Emotion Analysis, Cultural Context\n",
        "- 🎨 **Advanced Dashboard**: Real-time monitoring and story generation\n",
        "- 🔧 **Production APIs**: FastAPI with comprehensive endpoints\n",
        "- 📊 **Performance Monitoring**: Prometheus metrics and system health\n",
        "- 🐳 **Container Ready**: Docker and Kubernetes deployment\n",
        "- 🔐 **Enterprise Security**: Authentication, rate limiting, CORS\n",
        "\n",
        "### Repository: [GitHub - Telugu Story Engine](https://github.com/DIRAKHIL/super-agi-telugu-story-engine)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-header"
      },
      "source": [
        "## 🛠️ System Setup & Installation\n",
        "\n",
        "**⚠️ IMPORTANT**: This notebook requires GPU runtime for optimal performance.\n",
        "\n",
        "**Runtime Settings**: Runtime → Change runtime type → Hardware accelerator: GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup-system"
      },
      "outputs": [],
      "source": [
        "# 🔧 System Information & GPU Check\n",
        "import torch\n",
        "import sys\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"🎯 TELUGU STORY ENGINE - PRODUCTION SETUP\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"📅 Setup Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"🐍 Python Version: {sys.version}\")\n",
        "print(f\"🔥 PyTorch Version: {torch.__version__}\")\n",
        "print(f\"🚀 CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"💾 GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"🧠 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone-repository"
      },
      "outputs": [],
      "source": [
        "# 📥 Clone Production Repository\n",
        "!echo \"🔄 Cloning Telugu Story Engine Repository...\"\n",
        "!git clone https://github.com/DIRAKHIL/super-agi-telugu-story-engine.git\n",
        "%cd super-agi-telugu-story-engine\n",
        "!echo \"✅ Repository cloned successfully!\"\n",
        "!echo \"📁 Repository Contents:\"\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-dependencies"
      },
      "outputs": [],
      "source": [
        "# 📦 Install Production Dependencies\n",
        "!echo \"🔧 Installing Production Dependencies...\"\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Additional Colab-specific packages\n",
        "!pip install nest-asyncio pyngrok\n",
        "\n",
        "!echo \"✅ All dependencies installed successfully!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "models-header"
      },
      "source": [
        "## 🧠 AI Models Initialization\n",
        "\n",
        "Loading 4 production AI models for Telugu story generation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "initialize-models"
      },
      "outputs": [],
      "source": [
        "# 🧠 Initialize AI Models\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from src.core.model_manager import ModelManager\n",
        "from src.core.config import get_settings\n",
        "\n",
        "print(\"🚀 INITIALIZING AI MODELS\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Initialize settings and model manager\n",
        "settings = get_settings()\n",
        "model_manager = ModelManager(settings)\n",
        "\n",
        "# Load all models\n",
        "async def load_models():\n",
        "    print(\"📥 Loading Telugu BERT model...\")\n",
        "    await model_manager.load_model(\"telugu_bert\")\n",
        "    print(\"✅ Telugu BERT loaded\")\n",
        "    \n",
        "    print(\"📥 Loading Telugu GPT-2 model...\")\n",
        "    await model_manager.load_model(\"telugu_gpt\")\n",
        "    print(\"✅ Telugu GPT-2 loaded\")\n",
        "    \n",
        "    print(\"📥 Loading Emotion Analysis model...\")\n",
        "    await model_manager.load_model(\"emotion_model\")\n",
        "    print(\"✅ Emotion model loaded\")\n",
        "    \n",
        "    print(\"📥 Loading Cultural Context model...\")\n",
        "    await model_manager.load_model(\"cultural_model\")\n",
        "    print(\"✅ Cultural model loaded\")\n",
        "    \n",
        "    return model_manager\n",
        "\n",
        "# Load models\n",
        "model_manager = await load_models()\n",
        "\n",
        "print(\"\\n🎉 ALL AI MODELS LOADED SUCCESSFULLY!\")\n",
        "print(f\"💾 Total Models: {len(model_manager.models)}\")\n",
        "print(\"🔥 System ready for story generation!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "api-header"
      },
      "source": [
        "## 🌐 Production API Server\n",
        "\n",
        "Starting the FastAPI server with all production features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "start-api-server"
      },
      "outputs": [],
      "source": [
        "# 🌐 Start Production API Server\n",
        "import threading\n",
        "import time\n",
        "from src.api.main import create_app\n",
        "import uvicorn\n",
        "\n",
        "# Create FastAPI app with all production features\n",
        "app = create_app()\n",
        "\n",
        "# Configure server\n",
        "config = uvicorn.Config(\n",
        "    app=app,\n",
        "    host=\"0.0.0.0\",\n",
        "    port=8000,\n",
        "    log_level=\"info\",\n",
        "    access_log=True\n",
        ")\n",
        "\n",
        "server = uvicorn.Server(config)\n",
        "\n",
        "# Start server in background thread\n",
        "def run_server():\n",
        "    asyncio.run(server.serve())\n",
        "\n",
        "server_thread = threading.Thread(target=run_server, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "# Wait for server to start\n",
        "time.sleep(5)\n",
        "\n",
        "print(\"🚀 API SERVER STARTED!\")\n",
        "print(\"=\" * 30)\n",
        "print(\"📡 Server URL: http://localhost:8000\")\n",
        "print(\"📚 API Docs: http://localhost:8000/api/v2/docs\")\n",
        "print(\"💓 Health Check: http://localhost:8000/health\")\n",
        "print(\"📊 Metrics: http://localhost:8000/metrics\")\n",
        "print(\"✅ Server is running in background!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup-ngrok"
      },
      "outputs": [],
      "source": [
        "# 🌍 Setup Public Access with ngrok (Optional)\n",
        "from pyngrok import ngrok\n",
        "import requests\n",
        "\n",
        "# Create public tunnel\n",
        "public_tunnel = ngrok.connect(8000)\n",
        "public_url = public_tunnel.public_url\n",
        "\n",
        "print(\"🌍 PUBLIC ACCESS ENABLED!\")\n",
        "print(\"=\" * 35)\n",
        "print(f\"🔗 Public URL: {public_url}\")\n",
        "print(f\"📚 Public API Docs: {public_url}/api/v2/docs\")\n",
        "print(f\"💓 Public Health: {public_url}/health\")\n",
        "print(\"\\n⚠️  Note: This URL is publicly accessible!\")\n",
        "\n",
        "# Test public endpoint\n",
        "try:\n",
        "    response = requests.get(f\"{public_url}/health\", timeout=10)\n",
        "    if response.status_code == 200:\n",
        "        print(\"✅ Public endpoint is working!\")\n",
        "    else:\n",
        "        print(f\"⚠️  Public endpoint returned: {response.status_code}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Public endpoint test failed: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "testing-header"
      },
      "source": [
        "## 🧪 Comprehensive System Testing\n",
        "\n",
        "Running production tests to validate all components:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run-comprehensive-tests"
      },
      "outputs": [],
      "source": [
        "# 🧪 Run Comprehensive Tests\n",
        "import requests\n",
        "import json\n",
        "\n",
        "base_url = \"http://localhost:8000\"\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": \"Bearer demo-token\"\n",
        "}\n",
        "\n",
        "print(\"🧪 COMPREHENSIVE SYSTEM TESTING\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Test 1: Health Check\n",
        "print(\"\\n1️⃣ Testing Health Check...\")\n",
        "try:\n",
        "    response = requests.get(f\"{base_url}/health\", timeout=10)\n",
        "    if response.status_code == 200:\n",
        "        print(\"✅ Health Check: PASSED\")\n",
        "    else:\n",
        "        print(f\"❌ Health Check: FAILED (HTTP {response.status_code})\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Health Check: ERROR - {e}\")\n",
        "\n",
        "# Test 2: System Status\n",
        "print(\"\\n2️⃣ Testing System Status...\")\n",
        "try:\n",
        "    response = requests.get(f\"{base_url}/api/v2/system/status\", headers=headers, timeout=30)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        models = data.get('model_status', {})\n",
        "        loaded_models = [name for name, status in models.items() if status == 'loaded']\n",
        "        print(f\"✅ System Status: PASSED ({len(loaded_models)}/4 models loaded)\")\n",
        "        print(f\"   📊 Models: {', '.join(loaded_models)}\")\n",
        "    else:\n",
        "        print(f\"❌ System Status: FAILED (HTTP {response.status_code})\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ System Status: ERROR - {e}\")\n",
        "\n",
        "# Test 3: Story Generation\n",
        "print(\"\\n3️⃣ Testing Story Generation...\")\n",
        "try:\n",
        "    payload = {\n",
        "        \"prompt\": \"ఒక చిన్న పిల్లవాడు తన స్నేహితుడితో ఆట ఆడుతున్న కథ\",\n",
        "        \"length\": 500,\n",
        "        \"cultural_context\": \"traditional_telugu\",\n",
        "        \"story_type\": \"adventure\",\n",
        "        \"target_audience\": \"children\"\n",
        "    }\n",
        "    \n",
        "    response = requests.post(f\"{base_url}/api/v2/stories/generate\",\n",
        "                           headers=headers, json=payload, timeout=120)\n",
        "    \n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        content = data.get('content', '')\n",
        "        word_count = data.get('metadata', {}).get('word_count', 0)\n",
        "        print(f\"✅ Story Generation: PASSED\")\n",
        "        print(f\"   📝 Generated: {len(content)} characters, {word_count} words\")\n",
        "        print(f\"   🎭 Story Preview: {content[:100]}...\")\n",
        "    else:\n",
        "        print(f\"❌ Story Generation: FAILED (HTTP {response.status_code})\")\n",
        "        print(f\"   Error: {response.text}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Story Generation: ERROR - {e}\")\n",
        "\n",
        "# Test 4: API Documentation\n",
        "print(\"\\n4️⃣ Testing API Documentation...\")\n",
        "try:\n",
        "    response = requests.get(f\"{base_url}/api/v2/docs\", timeout=10)\n",
        "    if response.status_code == 200:\n",
        "        print(\"✅ API Documentation: PASSED\")\n",
        "    else:\n",
        "        print(f\"❌ API Documentation: FAILED (HTTP {response.status_code})\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ API Documentation: ERROR - {e}\")\n",
        "\n",
        "print(\"\\n🎉 TESTING COMPLETE!\")\n",
        "print(\"📊 Check results above for system status\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dashboard-header"
      },
      "source": [
        "## 📊 Advanced Dashboard\n",
        "\n",
        "Starting the Streamlit dashboard for real-time monitoring:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "start-dashboard"
      },
      "outputs": [],
      "source": [
        "# 📊 Start Advanced Dashboard\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "print(\"🚀 STARTING ADVANCED DASHBOARD\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "# Start Streamlit dashboard in background\n",
        "dashboard_process = subprocess.Popen([\n",
        "    \"streamlit\", \"run\", \"src/dashboard/main.py\",\n",
        "    \"--server.port\", \"8501\",\n",
        "    \"--server.address\", \"0.0.0.0\",\n",
        "    \"--server.headless\", \"true\",\n",
        "    \"--browser.gatherUsageStats\", \"false\"\n",
        "], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "# Wait for dashboard to start\n",
        "time.sleep(10)\n",
        "\n",
        "# Create public tunnel for dashboard\n",
        "dashboard_tunnel = ngrok.connect(8501)\n",
        "dashboard_url = dashboard_tunnel.public_url\n",
        "\n",
        "print(\"✅ DASHBOARD STARTED SUCCESSFULLY!\")\n",
        "print(f\"🔗 Dashboard URL: {dashboard_url}\")\n",
        "print(f\"📊 Local URL: http://localhost:8501\")\n",
        "print(\"\\n🎯 Dashboard Features:\")\n",
        "print(\"• Real-time system monitoring\")\n",
        "print(\"• AI model status and metrics\")\n",
        "print(\"• Interactive story generation\")\n",
        "print(\"• Performance analytics\")\n",
        "print(\"• System health visualization\")\n",
        "\n",
        "print(f\"\\n🌍 Access your dashboard: {dashboard_url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "interactive-header"
      },
      "source": [
        "## 🎭 Interactive Story Generation\n",
        "\n",
        "Generate Telugu stories with different parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "interactive-story-generation"
      },
      "outputs": [],
      "source": [
        "# 🎭 Interactive Story Generation\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# Story generation function\n",
        "def generate_story(prompt, length, cultural_context, story_type, target_audience):\n",
        "    base_url = \"http://localhost:8000\"\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": \"Bearer demo-token\"\n",
        "    }\n",
        "    \n",
        "    payload = {\n",
        "        \"prompt\": prompt,\n",
        "        \"length\": length,\n",
        "        \"cultural_context\": cultural_context,\n",
        "        \"story_type\": story_type,\n",
        "        \"target_audience\": target_audience\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        print(\"🔄 Generating story...\")\n",
        "        response = requests.post(f\"{base_url}/api/v2/stories/generate\",\n",
        "                               headers=headers, json=payload, timeout=120)\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            \n",
        "            # Display story\n",
        "            clear_output(wait=True)\n",
        "            print(\"🎉 STORY GENERATED SUCCESSFULLY!\")\n",
        "            print(\"=\" * 40)\n",
        "            print(f\"📖 Title: {data.get('title', 'Telugu Story')}\")\n",
        "            print(f\"🎭 Type: {story_type.title()}\")\n",
        "            print(f\"🌍 Context: {cultural_context.replace('_', ' ').title()}\")\n",
        "            print(f\"👥 Audience: {target_audience.replace('_', ' ').title()}\")\n",
        "            print(\"\\n📝 STORY CONTENT:\")\n",
        "            print(\"-\" * 40)\n",
        "            print(data.get('content', 'No content generated'))\n",
        "            print(\"-\" * 40)\n",
        "            \n",
        "            # Display metadata\n",
        "            metadata = data.get('metadata', {})\n",
        "            print(f\"\\n📊 STORY METRICS:\")\n",
        "            print(f\"• Word Count: {metadata.get('word_count', 0)}\")\n",
        "            print(f\"• Character Count: {metadata.get('character_count', 0)}\")\n",
        "            print(f\"• Quality Score: {metadata.get('quality_score', 0):.2f}\")\n",
        "            print(f\"• Generation Time: {metadata.get('generation_time', 0):.2f}s\")\n",
        "            print(f\"• Cultural Authenticity: {metadata.get('cultural_authenticity_score', 0):.2f}\")\n",
        "            \n",
        "            # Display English summary\n",
        "            if data.get('english_summary'):\n",
        "                print(f\"\\n🌐 ENGLISH SUMMARY:\")\n",
        "                print(data.get('english_summary'))\n",
        "                \n",
        "        else:\n",
        "            clear_output(wait=True)\n",
        "            print(f\"❌ Story generation failed: HTTP {response.status_code}\")\n",
        "            print(f\"Error: {response.text}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        clear_output(wait=True)\n",
        "        print(f\"❌ Error generating story: {e}\")\n",
        "\n",
        "# Create interactive widgets\n",
        "prompt_widget = widgets.Textarea(\n",
        "    value=\"ఒక చిన్న పిల్లవాడు తన కలలను నెరవేర్చుకునే కథ\",\n",
        "    placeholder=\"Enter your Telugu story prompt...\",\n",
        "    description=\"Story Prompt:\",\n",
        "    style={'description_width': 'initial'},\n",
        "    layout=widgets.Layout(width='100%', height='80px')\n",
        ")\n",
        "\n",
        "length_widget = widgets.IntSlider(\n",
        "    value=500,\n",
        "    min=500,\n",
        "    max=2000,\n",
        "    step=100,\n",
        "    description=\"Story Length:\",\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "cultural_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Traditional Telugu', 'traditional_telugu'),\n",
        "        ('Contemporary Telugu', 'contemporary_telugu'),\n",
        "        ('Rural Telugu', 'rural_telugu'),\n",
        "        ('Coastal Andhra', 'coastal_andhra'),\n",
        "        ('Rayalaseema', 'rayalaseema'),\n",
        "        ('Telangana', 'telangana'),\n",
        "        ('Diaspora', 'diaspora')\n",
        "    ],\n",
        "    value='traditional_telugu',\n",
        "    description=\"Cultural Context:\",\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "story_type_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Adventure', 'adventure'),\n",
        "        ('Drama', 'drama'),\n",
        "        ('Comedy', 'comedy'),\n",
        "        ('Family', 'family'),\n",
        "        ('Romance', 'romance'),\n",
        "        ('Mystery', 'mystery'),\n",
        "        ('Fantasy', 'fantasy')\n",
        "    ],\n",
        "    value='adventure',\n",
        "    description=\"Story Type:\",\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "audience_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Children', 'children'),\n",
        "        ('Young Adults', 'young_adults'),\n",
        "        ('Adults', 'adults'),\n",
        "        ('All Ages', 'all_ages')\n",
        "    ],\n",
        "    value='children',\n",
        "    description=\"Target Audience:\",\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "generate_button = widgets.Button(\n",
        "    description=\"🎭 Generate Telugu Story\",\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='300px', height='50px')\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def on_generate_click(b):\n",
        "    with output_area:\n",
        "        generate_story(\n",
        "            prompt_widget.value,\n",
        "            length_widget.value,\n",
        "            cultural_widget.value,\n",
        "            story_type_widget.value,\n",
        "            audience_widget.value\n",
        "        )\n",
        "\n",
        "generate_button.on_click(on_generate_click)\n",
        "\n",
        "# Display interface\n",
        "print(\"🎭 INTERACTIVE TELUGU STORY GENERATOR\")\n",
        "print(\"=\" * 40)\n",
        "print(\"Configure your story parameters and click generate:\")\n",
        "\n",
        "display(widgets.VBox([\n",
        "    prompt_widget,\n",
        "    widgets.HBox([length_widget, cultural_widget]),\n",
        "    widgets.HBox([story_type_widget, audience_widget]),\n",
        "    generate_button,\n",
        "    output_area\n",
        "]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "performance-header"
      },
      "source": [
        "## 📈 Performance Monitoring\n",
        "\n",
        "Real-time system performance and metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "performance-monitoring"
      },
      "outputs": [],
      "source": [
        "# 📈 Performance Monitoring Dashboard\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "def get_system_metrics():\n",
        "    \"\"\"Get current system metrics\"\"\"\n",
        "    try:\n",
        "        response = requests.get(\"http://localhost:8000/api/v2/system/status\", \n",
        "                              headers={\"Authorization\": \"Bearer demo-token\"}, \n",
        "                              timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "    except:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "def display_performance_dashboard():\n",
        "    \"\"\"Display real-time performance dashboard\"\"\"\n",
        "    print(\"📈 REAL-TIME PERFORMANCE DASHBOARD\")\n",
        "    print(\"=\" * 45)\n",
        "    \n",
        "    metrics = get_system_metrics()\n",
        "    if not metrics:\n",
        "        print(\"❌ Unable to fetch system metrics\")\n",
        "        return\n",
        "    \n",
        "    # System Status\n",
        "    print(f\"🟢 System Status: {metrics.get('status', 'unknown').upper()}\")\n",
        "    print(f\"⏱️  Uptime: {metrics.get('uptime', 0):.1f} seconds\")\n",
        "    print(f\"📊 Last Updated: {metrics.get('last_updated', 'unknown')}\")\n",
        "    \n",
        "    # Model Status\n",
        "    print(\"\\n🧠 AI MODELS STATUS:\")\n",
        "    model_status = metrics.get('model_status', {})\n",
        "    for model, status in model_status.items():\n",
        "        status_icon = \"✅\" if status == \"loaded\" else \"❌\"\n",
        "        print(f\"   {status_icon} {model.replace('_', ' ').title()}: {status}\")\n",
        "    \n",
        "    # Memory Usage\n",
        "    print(\"\\n💾 MEMORY USAGE:\")\n",
        "    memory_usage = metrics.get('memory_usage', {})\n",
        "    total_memory = sum(memory_usage.values())\n",
        "    print(f\"   📊 Total Memory: {total_memory:.1f} MB\")\n",
        "    for model, memory in memory_usage.items():\n",
        "        percentage = (memory / total_memory * 100) if total_memory > 0 else 0\n",
        "        print(f\"   • {model.replace('_', ' ').title()}: {memory:.1f} MB ({percentage:.1f}%)\")\n",
        "    \n",
        "    # Performance Metrics\n",
        "    print(\"\\n⚡ PERFORMANCE METRICS:\")\n",
        "    perf = metrics.get('performance_metrics', {})\n",
        "    print(f\"   🚀 Requests/min: {perf.get('requests_per_minute', 0)}\")\n",
        "    print(f\"   ⏱️  Avg Response Time: {perf.get('avg_response_time', 0):.2f}s\")\n",
        "    print(f\"   ❌ Error Rate: {perf.get('error_rate', 0):.2%}\")\n",
        "    \n",
        "    # Active Agents\n",
        "    agents = metrics.get('active_agents', [])\n",
        "    print(f\"\\n🤖 ACTIVE AGENTS: {len(agents)}\")\n",
        "    for agent in agents:\n",
        "        status_icon = \"🟢\" if agent.get('status') == 'active' else \"🟡\"\n",
        "        print(f\"   {status_icon} {agent.get('agent_type', 'Unknown')}: {agent.get('status', 'unknown')}\")\n",
        "        print(f\"      Memory: {agent.get('memory_usage', 0):.1f} MB\")\n",
        "        print(f\"      Confidence: {agent.get('confidence', 0):.2f}\")\n",
        "    \n",
        "    # Create memory usage visualization\n",
        "    if memory_usage:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        \n",
        "        # Memory usage pie chart\n",
        "        plt.subplot(1, 2, 1)\n",
        "        labels = [model.replace('_', ' ').title() for model in memory_usage.keys()]\n",
        "        sizes = list(memory_usage.values())\n",
        "        colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']\n",
        "        \n",
        "        plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
        "        plt.title('AI Model Memory Usage Distribution')\n",
        "        \n",
        "        # Performance metrics bar chart\n",
        "        plt.subplot(1, 2, 2)\n",
        "        metrics_names = ['Requests/min', 'Avg Response (s)', 'Error Rate (%)']\n",
        "        metrics_values = [\n",
        "            perf.get('requests_per_minute', 0),\n",
        "            perf.get('avg_response_time', 0),\n",
        "            perf.get('error_rate', 0) * 100\n",
        "        ]\n",
        "        \n",
        "        bars = plt.bar(metrics_names, metrics_values, color=['#4CAF50', '#2196F3', '#FF5722'])\n",
        "        plt.title('System Performance Metrics')\n",
        "        plt.xticks(rotation=45)\n",
        "        \n",
        "        # Add value labels on bars\n",
        "        for bar, value in zip(bars, metrics_values):\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
        "                    f'{value:.1f}', ha='center', va='bottom')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Display dashboard\n",
        "display_performance_dashboard()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "api-examples-header"
      },
      "source": [
        "## 🔧 API Usage Examples\n",
        "\n",
        "Complete examples of using the production API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "api-examples"
      },
      "outputs": [],
      "source": [
        "# 🔧 Complete API Usage Examples\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "base_url = \"http://localhost:8000\"\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": \"Bearer demo-token\"\n",
        "}\n",
        "\n",
        "print(\"🔧 COMPLETE API USAGE EXAMPLES\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Example 1: Basic Story Generation\n",
        "print(\"\\n1️⃣ BASIC STORY GENERATION\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "basic_payload = {\n",
        "    \"prompt\": \"రాజకుమారుడు ఒక మాయా అడవిలో సాహసయాత్ర చేసే కథ\",\n",
        "    \"length\": 500,\n",
        "    \"cultural_context\": \"traditional_telugu\",\n",
        "    \"story_type\": \"adventure\",\n",
        "    \"target_audience\": \"children\"\n",
        "}\n",
        "\n",
        "print(\"📤 Request:\")\n",
        "print(f\"POST {base_url}/api/v2/stories/generate\")\n",
        "print(json.dumps(basic_payload, indent=2, ensure_ascii=False))\n",
        "\n",
        "try:\n",
        "    response = requests.post(f\"{base_url}/api/v2/stories/generate\",\n",
        "                           headers=headers, json=basic_payload, timeout=60)\n",
        "    print(f\"\\n📥 Response: HTTP {response.status_code}\")\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        print(f\"✅ Story ID: {data.get('id')}\")\n",
        "        print(f\"📖 Title: {data.get('title')}\")\n",
        "        print(f\"📝 Content Length: {len(data.get('content', ''))} chars\")\n",
        "        print(f\"🎯 Quality Score: {data.get('metadata', {}).get('quality_score', 0):.2f}\")\n",
        "    else:\n",
        "        print(f\"❌ Error: {response.text}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Request failed: {e}\")\n",
        "\n",
        "# Example 2: Advanced Story Generation\n",
        "print(\"\\n\\n2️⃣ ADVANCED STORY GENERATION\")\n",
        "print(\"-\" * 35)\n",
        "\n",
        "advanced_payload = {\n",
        "    \"prompt\": \"నగరంలో ఒక యువతి తన కెరీర్ కోసం పోరాడే కథ\",\n",
        "    \"length\": 800,\n",
        "    \"cultural_context\": \"contemporary_telugu\",\n",
        "    \"story_type\": \"drama\",\n",
        "    \"target_audience\": \"adults\",\n",
        "    \"characters\": [\n",
        "        {\"name\": \"ప్రియ\", \"role\": \"protagonist\", \"traits\": [\"determined\", \"intelligent\"]},\n",
        "        {\"name\": \"రాజు\", \"role\": \"mentor\", \"traits\": [\"wise\", \"supportive\"]}\n",
        "    ],\n",
        "    \"themes\": [\"perseverance\", \"family_support\", \"career_growth\"],\n",
        "    \"setting\": {\n",
        "        \"location\": \"హైదరాబాద్\",\n",
        "        \"time_period\": \"contemporary\",\n",
        "        \"atmosphere\": \"urban_professional\"\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"📤 Request:\")\n",
        "print(f\"POST {base_url}/api/v2/stories/generate\")\n",
        "print(json.dumps(advanced_payload, indent=2, ensure_ascii=False))\n",
        "\n",
        "try:\n",
        "    response = requests.post(f\"{base_url}/api/v2/stories/generate\",\n",
        "                           headers=headers, json=advanced_payload, timeout=90)\n",
        "    print(f\"\\n📥 Response: HTTP {response.status_code}\")\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        print(f\"✅ Story ID: {data.get('id')}\")\n",
        "        print(f\"📖 Title: {data.get('title')}\")\n",
        "        print(f\"📝 Word Count: {data.get('metadata', {}).get('word_count', 0)}\")\n",
        "        print(f\"🎭 Emotional Arc: {len(data.get('emotional_arc', {}).get('emotional_progression', []))} beats\")\n",
        "        print(f\"👥 Characters: {data.get('character_analysis', {}).get('input_characters', 0)}\")\n",
        "    else:\n",
        "        print(f\"❌ Error: {response.text}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Request failed: {e}\")\n",
        "\n",
        "# Example 3: System Status Check\n",
        "print(\"\\n\\n3️⃣ SYSTEM STATUS CHECK\")\n",
        "print(\"-\" * 25)\n",
        "\n",
        "print(\"📤 Request:\")\n",
        "print(f\"GET {base_url}/api/v2/system/status\")\n",
        "\n",
        "try:\n",
        "    response = requests.get(f\"{base_url}/api/v2/system/status\", headers=headers, timeout=10)\n",
        "    print(f\"\\n📥 Response: HTTP {response.status_code}\")\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        print(f\"✅ System Status: {data.get('status')}\")\n",
        "        print(f\"⏱️  Uptime: {data.get('uptime', 0):.1f}s\")\n",
        "        print(f\"🧠 Models Loaded: {len([m for m, s in data.get('model_status', {}).items() if s == 'loaded'])}\")\n",
        "        print(f\"🤖 Active Agents: {len(data.get('active_agents', []))}\")\n",
        "        print(f\"💾 Total Memory: {sum(data.get('memory_usage', {}).values()):.1f} MB\")\n",
        "    else:\n",
        "        print(f\"❌ Error: {response.text}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Request failed: {e}\")\n",
        "\n",
        "# Example 4: Health Check\n",
        "print(\"\\n\\n4️⃣ HEALTH CHECK\")\n",
        "print(\"-\" * 15)\n",
        "\n",
        "print(\"📤 Request:\")\n",
        "print(f\"GET {base_url}/health\")\n",
        "\n",
        "try:\n",
        "    response = requests.get(f\"{base_url}/health\", timeout=5)\n",
        "    print(f\"\\n📥 Response: HTTP {response.status_code}\")\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        print(f\"✅ Status: {data.get('status')}\")\n",
        "        print(f\"📅 Timestamp: {data.get('timestamp')}\")\n",
        "        print(f\"🔢 Version: {data.get('version')}\")\n",
        "    else:\n",
        "        print(f\"❌ Error: {response.text}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Request failed: {e}\")\n",
        "\n",
        "print(\"\\n🎉 API EXAMPLES COMPLETE!\")\n",
        "print(\"📚 Visit the API docs for more endpoints and examples\")\n",
        "print(f\"🔗 API Documentation: {base_url}/api/v2/docs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deployment-header"
      },
      "source": [
        "## 🚀 Production Deployment\n",
        "\n",
        "Instructions for deploying to production environments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deployment-instructions"
      },
      "outputs": [],
      "source": [
        "# 🚀 Production Deployment Instructions\n",
        "print(\"🚀 PRODUCTION DEPLOYMENT GUIDE\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "print(\"\\n🐳 DOCKER DEPLOYMENT:\")\n",
        "print(\"-\" * 20)\n",
        "print(\"1. Build Docker image:\")\n",
        "print(\"   docker build -t telugu-story-engine .\")\n",
        "print(\"\\n2. Run container:\")\n",
        "print(\"   docker run -p 8000:8000 -p 8501:8501 telugu-story-engine\")\n",
        "print(\"\\n3. Access services:\")\n",
        "print(\"   • API: http://localhost:8000\")\n",
        "print(\"   • Dashboard: http://localhost:8501\")\n",
        "\n",
        "print(\"\\n☸️ KUBERNETES DEPLOYMENT:\")\n",
        "print(\"-\" * 25)\n",
        "print(\"1. Apply Kubernetes manifests:\")\n",
        "print(\"   kubectl apply -f k8s/\")\n",
        "print(\"\\n2. Check deployment status:\")\n",
        "print(\"   kubectl get pods -l app=telugu-story-engine\")\n",
        "print(\"\\n3. Access via LoadBalancer or Ingress\")\n",
        "\n",
        "print(\"\\n🌐 CLOUD DEPLOYMENT OPTIONS:\")\n",
        "print(\"-\" * 30)\n",
        "print(\"• AWS ECS/EKS with GPU instances\")\n",
        "print(\"• Google Cloud Run with GPU support\")\n",
        "print(\"• Azure Container Instances\")\n",
        "print(\"• DigitalOcean App Platform\")\n",
        "\n",
        "print(\"\\n⚙️ ENVIRONMENT VARIABLES:\")\n",
        "print(\"-\" * 25)\n",
        "env_vars = {\n",
        "    \"ENVIRONMENT\": \"production\",\n",
        "    \"API_HOST\": \"0.0.0.0\",\n",
        "    \"API_PORT\": \"8000\",\n",
        "    \"DASHBOARD_PORT\": \"8501\",\n",
        "    \"MODEL_CACHE_DIR\": \"/app/models\",\n",
        "    \"LOG_LEVEL\": \"INFO\",\n",
        "    \"REDIS_URL\": \"redis://redis:6379\",\n",
        "    \"PROMETHEUS_PORT\": \"9090\"\n",
        "}\n",
        "\n",
        "for key, value in env_vars.items():\n",
        "    print(f\"   {key}={value}\")\n",
        "\n",
        "print(\"\\n🔧 PRODUCTION CHECKLIST:\")\n",
        "print(\"-\" * 25)\n",
        "checklist = [\n",
        "    \"✅ GPU-enabled infrastructure\",\n",
        "    \"✅ Sufficient memory (8GB+ RAM)\",\n",
        "    \"✅ Persistent storage for models\",\n",
        "    \"✅ Load balancer configuration\",\n",
        "    \"✅ SSL/TLS certificates\",\n",
        "    \"✅ Monitoring and logging setup\",\n",
        "    \"✅ Backup and disaster recovery\",\n",
        "    \"✅ Security hardening\",\n",
        "    \"✅ Performance testing\",\n",
        "    \"✅ Documentation and runbooks\"\n",
        "]\n",
        "\n",
        "for item in checklist:\n",
        "    print(f\"   {item}\")\n",
        "\n",
        "print(\"\\n📊 MONITORING SETUP:\")\n",
        "print(\"-\" * 20)\n",
        "print(\"• Prometheus metrics: /metrics\")\n",
        "print(\"• Health checks: /health\")\n",
        "print(\"• System status: /api/v2/system/status\")\n",
        "print(\"• Grafana dashboards for visualization\")\n",
        "print(\"• Alert manager for notifications\")\n",
        "\n",
        "print(\"\\n🔐 SECURITY CONSIDERATIONS:\")\n",
        "print(\"-\" * 30)\n",
        "print(\"• API authentication with JWT tokens\")\n",
        "print(\"• Rate limiting per endpoint\")\n",
        "print(\"• CORS configuration\")\n",
        "print(\"• Input validation and sanitization\")\n",
        "print(\"• Security headers (HSTS, CSP, etc.)\")\n",
        "print(\"• Regular security updates\")\n",
        "\n",
        "print(\"\\n🎯 PERFORMANCE OPTIMIZATION:\")\n",
        "print(\"-\" * 35)\n",
        "print(\"• Model caching and preloading\")\n",
        "print(\"• Connection pooling\")\n",
        "print(\"• Async request handling\")\n",
        "print(\"• GPU memory optimization\")\n",
        "print(\"• Response compression\")\n",
        "print(\"• CDN for static assets\")\n",
        "\n",
        "print(\"\\n🎉 DEPLOYMENT COMPLETE!\")\n",
        "print(\"Your Telugu Story Engine is ready for production use!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion-header"
      },
      "source": [
        "## 🎉 Conclusion\n",
        "\n",
        "### 🏆 Production-Ready Telugu Story Engine Successfully Deployed!\n",
        "\n",
        "**✅ What You've Accomplished:**\n",
        "- 🧠 **4 Real AI Models** loaded and operational\n",
        "- 🌐 **Production API Server** with comprehensive endpoints\n",
        "- 📊 **Advanced Dashboard** with real-time monitoring\n",
        "- 🧪 **Complete Test Suite** validating all components\n",
        "- 🔧 **Interactive Story Generation** with customizable parameters\n",
        "- 📈 **Performance Monitoring** with detailed metrics\n",
        "- 🚀 **Deployment Ready** for production environments\n",
        "\n",
        "**🎯 Key Features:**\n",
        "- **NO MOCKS** - All AI models are real and functional\n",
        "- **NO FALLBACKS** - Production-grade implementation\n",
        "- **NO DEMOS** - Fully operational system\n",
        "- **100% Open Source** - Complete transparency\n",
        "\n",
        "**🔗 Access Your System:**\n",
        "- **API Server**: Available at the ngrok URL above\n",
        "- **Dashboard**: Interactive Streamlit interface\n",
        "- **Documentation**: Complete API docs with examples\n",
        "- **Monitoring**: Real-time performance metrics\n",
        "\n",
        "**📚 Next Steps:**\n",
        "1. Explore the interactive story generation\n",
        "2. Monitor system performance in real-time\n",
        "3. Test different story parameters and contexts\n",
        "4. Deploy to your production environment\n",
        "5. Integrate with your applications via API\n",
        "\n",
        "**🌟 Repository**: [GitHub - Telugu Story Engine](https://github.com/DIRAKHIL/super-agi-telugu-story-engine)\n",
        "\n",
        "---\n",
        "\n",
        "### 🎭 Happy Story Generation! 🎭\n",
        "\n",
        "Your Telugu Story Engine is now fully operational and ready to generate authentic Telugu stories with real AI intelligence!"
      ]
    }
  ]
}